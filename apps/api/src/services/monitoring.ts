import { FastifyInstance, FastifyRequest, FastifyReply } from 'fastify';
import pino, { Logger } from 'pino';
import { createWriteStream } from 'fs';
import { RedisCacheService } from './redis-cache';
import { performance } from 'perf_hooks';
import { hostname } from 'os';
import { randomUUID } from 'crypto';

export interface MonitoringConfig {
  logging: {
    level: 'debug' | 'info' | 'warn' | 'error';
    enableFileLogging: boolean;
    logRotation: boolean;
    maxFiles: number;
    maxSize: string;
    enableStructuredLogging: boolean;
  };
  metrics: {
    enableRequestMetrics: boolean;
    enablePerformanceMetrics: boolean;
    enableBusinessMetrics: boolean;
    metricsRetention: number; // days
  };
  alerting: {
    enableAlerts: boolean;
    errorThreshold: number;
    responseTimeThreshold: number;
    webhookUrl?: string;
  };
  tracing: {
    enableTracing: boolean;
    sampleRate: number;
    enableSpanLogging: boolean;
  };
}

export interface RequestMetrics {
  requestId: string;
  method: string;
  url: string;
  userAgent?: string;
  ip: string;
  userId?: string;
  startTime: number;
  endTime?: number;
  responseTime?: number;
  statusCode?: number;
  error?: string;
  userAgent: string;
  contentLength?: number;
}

export interface PerformanceMetrics {
  timestamp: Date;
  cpu: NodeJS.CpuUsage;
  memory: NodeJS.MemoryUsage;
  uptime: number;
  eventLoop: {
    delay: number;
    utilization: number;
  };
  gc?: {
    collections: number;
    duration: number;
  };
}

export interface BusinessMetrics {
  event: string;
  data: any;
  timestamp: Date;
  userId?: string;
  sessionId?: string;
  metadata?: Record<string, any>;
}

export interface ErrorEvent {
  id: string;
  message: string;
  stack?: string;
  level: 'error' | 'fatal';
  timestamp: Date;
  context: {
    requestId?: string;
    userId?: string;
    ip?: string;
    userAgent?: string;
    method?: string;
    url?: string;
  };
  tags?: string[];
  fingerprint?: string;
}

export interface AlertEvent {
  id: string;
  type: 'error_rate' | 'response_time' | 'system' | 'business';
  severity: 'low' | 'medium' | 'high' | 'critical';
  title: string;
  message: string;
  timestamp: Date;
  data?: any;
  resolved?: boolean;
  resolvedAt?: Date;
}

/**
 * Comprehensive Monitoring and Logging Service
 * 
 * Features:
 * - Structured logging with Pino
 * - Request/response logging and metrics
 * - Performance monitoring
 * - Error tracking and aggregation
 * - Business metrics collection
 * - Real-time alerting
 * - Distributed tracing
 * - Log aggregation and search
 * - Dashboard metrics
 * - Health monitoring
 * - Custom event tracking
 * - Memory leak detection
 */
export class MonitoringService {
  private logger: Logger;
  private redis: RedisCacheService;
  private config: MonitoringConfig;
  private activeRequests: Map<string, RequestMetrics> = new Map();
  private performanceInterval?: NodeJS.Timer;
  private alertHistory: AlertEvent[] = [];
  private errorFingerprints: Map<string, { count: number; lastSeen: Date }> = new Map();

  constructor(redis: RedisCacheService, config: Partial<MonitoringConfig> = {}) {
    this.redis = redis;
    this.config = {
      logging: {
        level: 'info',
        enableFileLogging: true,
        logRotation: true,
        maxFiles: 10,
        maxSize: '100MB',
        enableStructuredLogging: true,
        ...config.logging
      },
      metrics: {
        enableRequestMetrics: true,
        enablePerformanceMetrics: true,
        enableBusinessMetrics: true,
        metricsRetention: 30,
        ...config.metrics
      },
      alerting: {
        enableAlerts: true,
        errorThreshold: 10, // errors per minute
        responseTimeThreshold: 5000, // 5 seconds
        ...config.alerting
      },
      tracing: {
        enableTracing: true,
        sampleRate: 0.1, // 10% of requests
        enableSpanLogging: true,
        ...config.tracing
      }
    };

    this.setupLogger();
    this.startPerformanceMonitoring();
    this.setupErrorHandling();
  }

  private setupLogger(): void {
    const loggerConfig: any = {
      level: this.config.logging.level,
      timestamp: pino.stdTimeFunctions.isoTime,
      formatters: {
        level: (label: string) => ({ level: label })
      }
    };

    if (this.config.logging.enableStructuredLogging) {
      loggerConfig.serializers = {
        req: (req: any) => ({
          id: req.id,
          method: req.method,
          url: req.url,
          headers: this.sanitizeHeaders(req.headers),
          remoteAddress: req.remoteAddress,
          remotePort: req.remotePort
        }),
        res: (res: any) => ({
          statusCode: res.statusCode,
          headers: this.sanitizeHeaders(res.getHeaders?.() || {})
        }),
        err: pino.stdSerializers.err
      };
    }

    // File logging setup
    if (this.config.logging.enableFileLogging) {
      const streams: any[] = [
        { level: 'info', stream: process.stdout },
        { level: 'error', stream: process.stderr }
      ];

      if (this.config.logging.logRotation) {
        // In production, you'd use a proper log rotation library
        streams.push({
          level: 'debug',
          stream: createWriteStream('./logs/app.log', { flags: 'a' })
        });
      }

      this.logger = pino(loggerConfig, pino.multistream(streams));
    } else {
      this.logger = pino(loggerConfig);
    }

    this.logger.info('ðŸ“Š Monitoring service initialized');
  }

  private sanitizeHeaders(headers: Record<string, any>): Record<string, any> {
    const sanitized = { ...headers };
    
    // Remove sensitive headers
    const sensitiveHeaders = ['authorization', 'cookie', 'x-api-key', 'x-auth-token'];
    sensitiveHeaders.forEach(header => {
      if (sanitized[header]) {
        sanitized[header] = '[REDACTED]';
      }
    });

    return sanitized;
  }

  private startPerformanceMonitoring(): void {
    if (!this.config.metrics.enablePerformanceMetrics) return;

    this.performanceInterval = setInterval(async () => {
      try {
        await this.collectPerformanceMetrics();
      } catch (error) {
        this.logger.error({ error }, 'Failed to collect performance metrics');
      }
    }, 30000); // Every 30 seconds
  }

  private setupErrorHandling(): void {
    process.on('uncaughtException', (error) => {
      this.logError({
        message: error.message,
        stack: error.stack,
        level: 'fatal',
        context: { source: 'uncaughtException' },
        tags: ['uncaught', 'fatal']
      });

      // Give time to log before exiting
      setTimeout(() => process.exit(1), 1000);
    });

    process.on('unhandledRejection', (reason, promise) => {
      this.logError({
        message: `Unhandled Rejection: ${reason}`,
        stack: reason instanceof Error ? reason.stack : undefined,
        level: 'error',
        context: { source: 'unhandledRejection', promise: promise.toString() },
        tags: ['unhandled', 'rejection']
      });
    });
  }

  // ============================================
  // REQUEST MONITORING
  // ============================================

  /**
   * Request monitoring middleware
   */
  async requestMiddleware(request: FastifyRequest, reply: FastifyReply): Promise<void> {
    if (!this.config.metrics.enableRequestMetrics) return;

    const requestId = randomUUID();
    const startTime = performance.now();
    
    // Add request ID to headers
    reply.header('X-Request-ID', requestId);

    const requestMetrics: RequestMetrics = {
      requestId,
      method: request.method,
      url: request.url,
      ip: request.ip,
      userId: (request as any).userId,
      userAgent: request.headers['user-agent'] || '',
      startTime
    };

    this.activeRequests.set(requestId, requestMetrics);

    // Log request start
    this.logger.info({
      req: request,
      requestId,
      msg: 'Request started'
    });

    // Add request context for tracing
    if (this.config.tracing.enableTracing && Math.random() < this.config.tracing.sampleRate) {
      (request as any).traceId = requestId;
      (request as any).spanId = randomUUID();
    }
  }

  /**
   * Response monitoring middleware
   */
  async responseMiddleware(request: FastifyRequest, reply: FastifyReply): Promise<void> {
    if (!this.config.metrics.enableRequestMetrics) return;

    const requestId = reply.getHeader('X-Request-ID') as string;
    const requestMetrics = this.activeRequests.get(requestId);

    if (!requestMetrics) return;

    const endTime = performance.now();
    const responseTime = endTime - requestMetrics.startTime;

    // Update metrics
    requestMetrics.endTime = endTime;
    requestMetrics.responseTime = responseTime;
    requestMetrics.statusCode = reply.statusCode;

    // Log response
    this.logger.info({
      req: request,
      res: reply,
      requestId,
      responseTime,
      msg: 'Request completed'
    });

    // Store metrics in Redis
    await this.storeRequestMetrics(requestMetrics);

    // Check for alerts
    await this.checkResponseTimeAlert(responseTime);

    // Clean up
    this.activeRequests.delete(requestId);

    // Trace logging
    if ((request as any).traceId && this.config.tracing.enableSpanLogging) {
      await this.logTrace({
        traceId: (request as any).traceId,
        spanId: (request as any).spanId,
        operation: `${request.method} ${request.url}`,
        duration: responseTime,
        tags: {
          'http.method': request.method,
          'http.url': request.url,
          'http.status_code': reply.statusCode,
          'user.id': (request as any).userId
        }
      });
    }
  }

  // ============================================
  // ERROR TRACKING
  // ============================================

  /**
   * Log and track errors
   */
  logError(errorData: {
    message: string;
    stack?: string;
    level: 'error' | 'fatal';
    context?: Record<string, any>;
    tags?: string[];
  }): void {
    const errorEvent: ErrorEvent = {
      id: randomUUID(),
      message: errorData.message,
      stack: errorData.stack,
      level: errorData.level,
      timestamp: new Date(),
      context: errorData.context || {},
      tags: errorData.tags,
      fingerprint: this.generateErrorFingerprint(errorData.message, errorData.stack)
    };

    // Log to console/file
    this.logger[errorData.level]({
      error: errorEvent,
      msg: errorData.message
    });

    // Track error frequency
    this.trackErrorFrequency(errorEvent);

    // Store in Redis for aggregation
    this.storeError(errorEvent);

    // Check for error rate alerts
    this.checkErrorRateAlert();
  }

  private generateErrorFingerprint(message: string, stack?: string): string {
    // Create a fingerprint for error grouping
    const content = stack ? stack.split('\n')[0] : message;
    return Buffer.from(content).toString('base64').substring(0, 16);
  }

  private trackErrorFrequency(error: ErrorEvent): void {
    if (!error.fingerprint) return;

    const existing = this.errorFingerprints.get(error.fingerprint);
    if (existing) {
      existing.count++;
      existing.lastSeen = error.timestamp;
    } else {
      this.errorFingerprints.set(error.fingerprint, {
        count: 1,
        lastSeen: error.timestamp
      });
    }
  }

  private async storeError(error: ErrorEvent): Promise<void> {
    const key = `errors:${error.timestamp.toISOString().split('T')[0]}`;
    await this.redis.lpush(key, error);
    await this.redis.expire(key, this.config.metrics.metricsRetention * 24 * 60 * 60);
  }

  // ============================================
  // PERFORMANCE MONITORING
  // ============================================

  private async collectPerformanceMetrics(): Promise<void> {
    const metrics: PerformanceMetrics = {
      timestamp: new Date(),
      cpu: process.cpuUsage(),
      memory: process.memoryUsage(),
      uptime: process.uptime(),
      eventLoop: {
        delay: 0, // Would need perf_hooks.monitorEventLoopDelay()
        utilization: 0 // Would need perf_hooks.performance.eventLoopUtilization()
      }
    };

    // Store metrics
    await this.storePerformanceMetrics(metrics);

    // Check for system alerts
    await this.checkSystemAlerts(metrics);

    this.logger.debug({ metrics }, 'Performance metrics collected');
  }

  private async storePerformanceMetrics(metrics: PerformanceMetrics): Promise<void> {
    const key = `performance:${hostname()}`;
    await this.redis.lpush(key, metrics);
    
    // Keep only last 2880 entries (24 hours of 30-second intervals)
    const count = await this.redis.llen(key);
    if (count > 2880) {
      await this.redis.redis.ltrim(key, 0, 2879);
    }
  }

  // ============================================
  // BUSINESS METRICS
  // ============================================

  /**
   * Track business events
   */
  async trackEvent(event: string, data: any, metadata?: Record<string, any>): Promise<void> {
    if (!this.config.metrics.enableBusinessMetrics) return;

    const businessMetric: BusinessMetrics = {
      event,
      data,
      timestamp: new Date(),
      userId: metadata?.userId,
      sessionId: metadata?.sessionId,
      metadata
    };

    // Log event
    this.logger.info({
      businessMetric,
      msg: `Business event: ${event}`
    });

    // Store in Redis
    await this.storeBusinessMetric(businessMetric);
  }

  private async storeBusinessMetric(metric: BusinessMetrics): Promise<void> {
    const date = metric.timestamp.toISOString().split('T')[0];
    const key = `business:${metric.event}:${date}`;
    
    await this.redis.lpush(key, metric);
    await this.redis.expire(key, this.config.metrics.metricsRetention * 24 * 60 * 60);

    // Also store in daily aggregation
    const dailyKey = `business:daily:${date}`;
    await this.redis.sadd(dailyKey, metric.event);
    await this.redis.expire(dailyKey, this.config.metrics.metricsRetention * 24 * 60 * 60);
  }

  // ============================================
  // ALERTING
  // ============================================

  private async checkErrorRateAlert(): Promise<void> {
    if (!this.config.alerting.enableAlerts) return;

    const oneMinuteAgo = Date.now() - 60 * 1000;
    const recentErrors = Array.from(this.errorFingerprints.values())
      .filter(error => error.lastSeen.getTime() > oneMinuteAgo)
      .reduce((total, error) => total + error.count, 0);

    if (recentErrors >= this.config.alerting.errorThreshold) {
      await this.createAlert({
        type: 'error_rate',
        severity: 'high',
        title: 'High Error Rate Detected',
        message: `${recentErrors} errors in the last minute (threshold: ${this.config.alerting.errorThreshold})`,
        data: { errorCount: recentErrors, threshold: this.config.alerting.errorThreshold }
      });
    }
  }

  private async checkResponseTimeAlert(responseTime: number): Promise<void> {
    if (!this.config.alerting.enableAlerts) return;

    if (responseTime > this.config.alerting.responseTimeThreshold) {
      await this.createAlert({
        type: 'response_time',
        severity: 'medium',
        title: 'Slow Response Time',
        message: `Request took ${responseTime}ms (threshold: ${this.config.alerting.responseTimeThreshold}ms)`,
        data: { responseTime, threshold: this.config.alerting.responseTimeThreshold }
      });
    }
  }

  private async checkSystemAlerts(metrics: PerformanceMetrics): Promise<void> {
    if (!this.config.alerting.enableAlerts) return;

    // Memory usage alert (>80% heap usage)
    const heapUsagePercent = (metrics.memory.heapUsed / metrics.memory.heapTotal) * 100;
    if (heapUsagePercent > 80) {
      await this.createAlert({
        type: 'system',
        severity: 'high',
        title: 'High Memory Usage',
        message: `Heap usage at ${heapUsagePercent.toFixed(1)}%`,
        data: { heapUsagePercent, memory: metrics.memory }
      });
    }

    // RSS memory alert (>1GB)
    if (metrics.memory.rss > 1024 * 1024 * 1024) {
      await this.createAlert({
        type: 'system',
        severity: 'medium',
        title: 'High RSS Memory Usage',
        message: `RSS memory usage: ${Math.round(metrics.memory.rss / 1024 / 1024)}MB`,
        data: { rss: metrics.memory.rss }
      });
    }
  }

  private async createAlert(alertData: Omit<AlertEvent, 'id' | 'timestamp' | 'resolved'>): Promise<void> {
    const alert: AlertEvent = {
      id: randomUUID(),
      timestamp: new Date(),
      resolved: false,
      ...alertData
    };

    // Store alert
    this.alertHistory.push(alert);
    await this.redis.lpush('alerts', alert);

    // Log alert
    this.logger.warn({ alert }, `Alert: ${alert.title}`);

    // Send webhook notification if configured
    if (this.config.alerting.webhookUrl) {
      await this.sendWebhookAlert(alert);
    }

    // Keep only last 1000 alerts in memory
    if (this.alertHistory.length > 1000) {
      this.alertHistory = this.alertHistory.slice(-1000);
    }
  }

  private async sendWebhookAlert(alert: AlertEvent): Promise<void> {
    if (!this.config.alerting.webhookUrl) return;

    try {
      // This would send to Slack, Discord, PagerDuty, etc.
      const payload = {
        text: `ðŸš¨ ${alert.severity.toUpperCase()} Alert: ${alert.title}`,
        details: {
          message: alert.message,
          severity: alert.severity,
          timestamp: alert.timestamp.toISOString(),
          data: alert.data
        }
      };

      // In a real implementation, you'd use fetch or axios
      console.log('ðŸ“¢ Webhook alert would be sent:', payload);
      
    } catch (error) {
      this.logger.error({ error }, 'Failed to send webhook alert');
    }
  }

  // ============================================
  // TRACING
  // ============================================

  private async logTrace(trace: {
    traceId: string;
    spanId: string;
    operation: string;
    duration: number;
    tags: Record<string, any>;
  }): Promise<void> {
    const traceData = {
      ...trace,
      timestamp: new Date(),
      service: 'cryb-api',
      host: hostname()
    };

    await this.redis.lpush(`trace:${trace.traceId}`, traceData);
    await this.redis.expire(`trace:${trace.traceId}`, 24 * 60 * 60); // 24 hours

    if (this.config.tracing.enableSpanLogging) {
      this.logger.debug({ trace: traceData }, 'Trace span logged');
    }
  }

  // ============================================
  // METRICS RETRIEVAL
  // ============================================

  /**
   * Get request metrics
   */
  async getRequestMetrics(timeRange: 'hour' | 'day' | 'week' = 'day'): Promise<any> {
    const endTime = Date.now();
    let startTime: number;

    switch (timeRange) {
      case 'hour':
        startTime = endTime - 60 * 60 * 1000;
        break;
      case 'week':
        startTime = endTime - 7 * 24 * 60 * 60 * 1000;
        break;
      default:
        startTime = endTime - 24 * 60 * 60 * 1000;
    }

    // This would aggregate request metrics from Redis
    return {
      totalRequests: 0,
      averageResponseTime: 0,
      errorRate: 0,
      statusCodes: {},
      topEndpoints: []
    };
  }

  /**
   * Get error summary
   */
  getErrorSummary(): {
    totalErrors: number;
    uniqueErrors: number;
    topErrors: Array<{ fingerprint: string; count: number; lastSeen: Date }>;
  } {
    const totalErrors = Array.from(this.errorFingerprints.values())
      .reduce((total, error) => total + error.count, 0);

    const topErrors = Array.from(this.errorFingerprints.entries())
      .map(([fingerprint, data]) => ({ fingerprint, ...data }))
      .sort((a, b) => b.count - a.count)
      .slice(0, 10);

    return {
      totalErrors,
      uniqueErrors: this.errorFingerprints.size,
      topErrors
    };
  }

  /**
   * Get active alerts
   */
  getActiveAlerts(): AlertEvent[] {
    return this.alertHistory.filter(alert => !alert.resolved);
  }

  /**
   * Get system status
   */
  async getSystemStatus(): Promise<{
    status: 'healthy' | 'degraded' | 'unhealthy';
    uptime: number;
    activeRequests: number;
    totalErrors: number;
    activeAlerts: number;
    lastMetricsUpdate: Date;
  }> {
    const errorSummary = this.getErrorSummary();
    const activeAlerts = this.getActiveAlerts();

    let status: 'healthy' | 'degraded' | 'unhealthy' = 'healthy';
    
    if (activeAlerts.some(alert => alert.severity === 'critical')) {
      status = 'unhealthy';
    } else if (activeAlerts.some(alert => alert.severity === 'high') || errorSummary.totalErrors > 50) {
      status = 'degraded';
    }

    return {
      status,
      uptime: process.uptime(),
      activeRequests: this.activeRequests.size,
      totalErrors: errorSummary.totalErrors,
      activeAlerts: activeAlerts.length,
      lastMetricsUpdate: new Date()
    };
  }

  // ============================================
  // PRIVATE HELPERS
  // ============================================

  private async storeRequestMetrics(metrics: RequestMetrics): Promise<void> {
    const date = new Date().toISOString().split('T')[0];
    const key = `requests:${date}`;
    
    await this.redis.lpush(key, metrics);
    await this.redis.expire(key, this.config.metrics.metricsRetention * 24 * 60 * 60);
  }

  // ============================================
  // PUBLIC API
  // ============================================

  /**
   * Get logger instance
   */
  getLogger(): Logger {
    return this.logger;
  }

  /**
   * Create child logger with context
   */
  createChildLogger(context: Record<string, any>): Logger {
    return this.logger.child(context);
  }

  /**
   * Close monitoring service
   */
  async close(): Promise<void> {
    if (this.performanceInterval) {
      clearInterval(this.performanceInterval);
    }

    this.logger.info('ðŸ“Š Monitoring service closed');
  }
}

/**
 * Create monitoring service
 */
export function createMonitoringService(
  redis: RedisCacheService,
  config: Partial<MonitoringConfig> = {}
): MonitoringService {
  return new MonitoringService(redis, config);
}

/**
 * Fastify plugin for monitoring service
 */
export async function monitoringPlugin(
  fastify: FastifyInstance,
  config: Partial<MonitoringConfig> = {}
) {
  const redis = (fastify as any).cache as RedisCacheService;
  const monitoring = createMonitoringService(redis, config);

  fastify.decorate('monitoring', monitoring);

  // Replace default logger
  fastify.log = monitoring.getLogger();

  // Add request/response monitoring hooks
  fastify.addHook('onRequest', async (request, reply) => {
    await monitoring.requestMiddleware(request, reply);
  });

  fastify.addHook('onResponse', async (request, reply) => {
    await monitoring.responseMiddleware(request, reply);
  });

  // Add error tracking
  fastify.setErrorHandler(async (error, request, reply) => {
    monitoring.logError({
      message: error.message,
      stack: error.stack,
      level: 'error',
      context: {
        requestId: reply.getHeader('X-Request-ID') as string,
        userId: (request as any).userId,
        ip: request.ip,
        userAgent: request.headers['user-agent'],
        method: request.method,
        url: request.url
      },
      tags: ['http', 'error']
    });

    // Send appropriate error response
    if (!reply.sent) {
      reply.code(error.statusCode || 500).send({
        success: false,
        error: error.message,
        requestId: reply.getHeader('X-Request-ID')
      });
    }
  });

  // Add cleanup on server close
  fastify.addHook('onClose', async () => {
    await monitoring.close();
  });

  console.log('ðŸ“Š Monitoring Service initialized with features:');
  console.log('   - Structured logging with Pino');
  console.log('   - Request/response tracking');
  console.log('   - Performance monitoring');
  console.log('   - Error tracking and aggregation');
  console.log('   - Business metrics collection');
  console.log('   - Real-time alerting');
  console.log('   - Distributed tracing');
  console.log('   - Health monitoring');
}